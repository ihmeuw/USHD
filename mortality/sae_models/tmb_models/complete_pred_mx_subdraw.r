####################################################################################################
## Description: Reads in the model draws, fixed effects, and labels generated by pred_mx and then
##              calculates the mx draws for a particular chunk of draws (read in by the array job).
##              Also calculates the age-standardized and all-age values.
##              Saves this chunk of draws for all ages/locations/races for each year separately.
##
## Passed args: dir [character] -- home directory for settings and final output
##              sex [integer] -- sex to generate predictions for
##              race [integer] -- race to generate predictions for
##              edu [integer] -- educational attainment group to generate predictions for
##              validate [logical] -- is this a validation model? if so, only mx draws for
##                areas in the validation set are created
##              resub [logical] -- are you resubmitting? if yes, it will not re-save files that already
##                exist (or where the final file with all draws exists)
##              * note that the range of subdraws is read in from an array job
##
## Requires:    prepped data
##              file specifying areas in the validation set, if validate is T (gs_file)
##              populations (pop_file)
##              age standard file (age_std_file)
##              draws generated by pred_mx ([dir]/initial_sims_[sex]_[race]_[edu].rds)
##              fixed effects generated by pred_mx ([dir]/fe_sims_[sex]_[race]_[edu].rds)
##              names of the effects used for subsetting the draws ([dir]/mean_[sex]_[race]_[edu].rds)
##
## Outputs:     mx draws and estimates, saved in separate files by year and draw "chunk":
##                "[dir]/mx_draws_[area_var]_[year]_[sex]_[race]_[edu]_[max_subdraw].rds"
##
####################################################################################################

stopifnot(grepl("mortality/sae_models$", getwd()))

library(R.utils)
library(data.table)
library(Matrix)
library(splines)
sourceDirectory("functions/", modifiedOnly=F)

set.seed(98121)

## Get settings ------------------------------------------------------------------------------------
args <- commandArgs(trailingOnly = TRUE)
dir <- args[1]
sex <- as.integer(args[2])
race <- as.integer(args[3])
edu <- as.integer(args[4])
validate <- as.logical(args[5])
resub <- as.logical(args[6])

get_settings(dir)

## Assuming that model is in FILEPATH, determine the location for this model on limited use
current_dir <- gsub("FILEPATH", "", dir)
lu_root <- file.path("FILEPATH", LU_folder, "FILEPATH")
lu_modeldir <- file.path(lu_root, current_dir)

## read in array arguments
## get the draw value
if (interactive()) {
  # don't need draw_args
  task_id = 1
  draw_val = c(1:50)
} else {
  draw_args <- fread(paste0(dir, "/draw_args_sex_", sex, "_", race, "_", edu, ".csv"))
  task_id <- ifelse(is.na(as.integer(Sys.getenv("SLURM_ARRAY_TASK_ID"))), 1, as.integer(Sys.getenv("SLURM_ARRAY_TASK_ID")))
  draw_val <- c(draw_args[task_id, start_draw]:draw_args[task_id, end_draw])
}

# print out all the variables that control the behavior of this script
# draw_val and task_id are not passed in as arguments but do control behavior
# This provides the information that distinguishes each array job in the job-output
cat(
  glue::glue(
    "Settings passed are:",
    "dir = '{dir}'",
    "sex = {sex}",
    "race = {race}",
    "edu = {edu}",
    "validate = {validate}",
    "resub = {resub}",
    "draw_val = c({min(draw_val)}:{max(draw_val)})",
    "task_id = {task_id}\n",
    "",
    .sep = "\n"
  )
)

# other settings
cat(
  glue::glue(
    "",
    "Other settings:",
    "model: {model}",
    "race_together = {race_together}",
    "edu_together = {edu_together}",
    "by_race = {by_race}",
    "by_edu = {by_edu}",
    "races =  c({paste(races, collapse = ', ')})",
    "edu_groups = c({paste(edu_groups, collapse = ', ')})\n",
    .sep = "\n"
  )
)

## Load data and model fit -------------------------------------------------------------------------
# Data must be read in from Limited Use
data <- readRDS(file.path(lu_modeldir, "data.rds"))

if("race_agg" %in% names(data)) {
  data <- data[race_agg == "granular"] # get rid of aggregate data in case this messes up this estimation
  
  data[,count := .N, by=c("area","year","sex","race","age","edu")]
  stopifnot(nrow(data[count > 1]) == 0)
  data[,count := NULL]

  # reset the key
  setkeyv(data, c("area", "year", "sex", "race", "edu", "age"))
}

# subset the data
data <- data[sex_fit == get("sex", .GlobalEnv) & race_fit == get("race", .GlobalEnv) & edu_fit == get("edu", .GlobalEnv), ]
loc <- fread("FILEPATH/merged_counties.csv")
states <- unique(loc$state) # for models with state effects

# If this is for education, it is necessary to remove unknown education. Non-reporting state-years
# were removed from the data temporarily before model fitting, in order to avoid fitting the model
# to unknown education data. Non-reporting state years were the only places that had unknown

# dropping non-reporting state-years, its dropping unknown education. This is is to ensure that we
# still have every county, sex, age, year, and education group that we want to model for. That is,
# we dropped non-reporting state years from fitting, but we still want to predict for non-reporting
# state years, so, we have to have them present. That is why the code below checks for square
# dimensions.
if (by_edu) {
  data <- data[edu != unknown_edu, ]

  # check that data is square. ie, it has all the things we want to predict for: all the ages,
  # sexes, years, locations, and education groups that we want results for.
  # naive test:
  num_expected_dims <- length(unique(ages)) * length(unique(years)) * length(unique(sex)) * dim(readRDS(adjmat_file))[1] * length(unique(edu_groups)) 
  num_existing_dims <- nrow(data)
  stopifnot(num_expected_dims == num_existing_dims)

  # full test: (values must have same encoding as data)
  expected_dims <-
    data.table(
      expand.grid(
        age = as.integer(factor(ages, levels = ages)) - 1L,
        year = as.integer(years - years[1]),
        sex = get("sex", .GlobalEnv),
        area = unique(readRDS(geoagg_files["natl"])[[area_var]]),
        edu = edu_groups
      )
    )
  all_equal_result <- all.equal(target = expected_dims,
            current =  data[, list(area, year, sex, age, edu)],
            ignore.col.order = T, ignore.row.order = T)

  message(glue::glue("all.equal() expected dims result: {all_equal_result}"))

  stopifnot(all_equal_result)

}

# the number of races is equal to the unique number of races once we have subsetted race_fit
races_to_model <- sort(unique(data$race))
num_r <- length(races_to_model)
edus_to_model <- unique(data$edu)
num_e <- length(edus_to_model)

stopifnot(num_e == length(unique(data$edu)))
stopifnot(num_r == length(unique(data$race)))

# get number of values for the rest of the variables
num_j <- max(data$area) + 1 # number of areas
num_t <- max(data$year) + 1 # number of years
num_a <- max(data$age) + 1 # number of ages
num_s <- length(unique(data$sex)) # sex was not indexed because this is just something we are trying
indexed_areas <- seq(0, num_j-1L)

# the simvars are not actually the draw vals because when the matrices get subset the column numbers change
simvars <- paste0("V", 1:length(draw_val))

# If a validation model, subset the data so that predictions are generated only for the validation
# set However, keep all race/ethnicities in the counties that are in the validation set. That is,
# keep all the counties in the validation set.
if (validate) {
  gs_mx <- readRDS(gs_file)
  gs_mx <- gs_mx[year %in% years, ]
  # drop race and edu because we want to keep all races in counties that have at least one race in
  # the validation set
  gs_mx[, `:=`(race = NULL, edu = NULL)]
  # get rid of duplicates in the counties that had more than one race
  gs <- unique(gs_mx[sex == get("sex", .GlobalEnv),
                     list(area = get(area_var))])
  data <- merge(gs, data, by = c("area"), all.x = T)
  stopifnot(!any(is.na(data)))
  setkeyv(data, c("area", "year", "sex"))  # spline model 3 fails if the key does not include sex
  rm(gs, gs_mx)
  gc()
}


## Break out by draws and predict each one separately
# Random effects
sims <- readRDS(paste0(dir, "/initial_sims_", sex, "_", race, "_", edu, ".rds"))
# Summed fixed effects (intercept and covariates)
fe <- readRDS(paste0(dir, "/fe_sims_", sex, "_", race, "_", edu, ".rds"))

# Tells us which column corresponds to which random effect
mean <- readRDS(paste0(dir, "/mean_", sex, "_", race, "_", edu, ".rds"))

# Subset to the draws of interest
sims <- sims[, draw_val]
fe <- fe[, draw_val]

# Get spline information, if present in settings.csv
if (!is.null(age_knots_spec)) {
  age_spline_info <- build_age_spline(ages, age_knots_spec)
  s_age <- as.data.table(age_spline_info[[1]])
}


if (!is.null(year_knots_num) | !is.null(year_knots_spec)) {
  if(!is.null(year_knots_spec)) {
    time_spline_info <- build_time_spline(years, year_knots_spec = year_knots_spec,
                                          detach_spline_19_21 = detach_spline_19_21,
                                          detach_spline_19_22 = detach_spline_19_22)
  } else {
    time_spline_info <- build_time_spline(years, year_knots_num = year_knots_num,
                                          detach_spline_19_21 = detach_spline_19_21,
                                          detach_spline_19_22 = detach_spline_19_22)
  }

  s_year <- as.data.table(time_spline_info[[1]])
}


# modify this specific covariate: prop_1989_revision This covariate is an "offset". in the fitting
# phase, we want to account for the effect of a state changing death certificate versions. so, we
# have this data, which acts like a covariate which should pick up that effect in the fitting phase.
# Here in the prediction phase, we want to remove that effect. To do this, we set the data to zero.
# That way the effect will not contribute to the prediction, and the effect of changing death
# certificate versions should be removed. The setting zero_covar_offset controls whether or not we
# want to zero it out.
if (!is.null(covars_offset)) {
  if (covars_offset %in% names(data) & zero_covar_offset) {
    message("ZEROING OUT covar_offset!!")
    data[, get("covars_offset") := 0]
  }
}


# First deal with the spline
re1 <- data.table(as.matrix(sims[names(mean) == "re1", ]))

# get the combinations of age/time spline bases, areas, and races and edus
combos <- as.data.table(expand.grid(y_spline = seq(1, ncol(s_year)),
                                    a_spline = seq(1, ncol(s_age)),
                                    area = indexed_areas,
                                    race = races_to_model,
                                    edu = edus_to_model))

stopifnot(nrow(re1) == nrow(combos))

re1 <- cbind(re1, combos)

s_age[, age := .I-1]
s_year[, year := .I-1]
s_year <- melt.data.table(s_year, id.vars="year", value.name = "y_spline_value", variable.name = "y_spline")
s_age <- melt.data.table(s_age, id.vars="age", value.name = "a_spline_value", variable.name = "a_spline")

s_year[, y_spline := as.integer(as.character(y_spline))]
s_age[, a_spline := as.integer(as.character(a_spline))]

re1 <- merge(re1, s_year, by="y_spline", allow.cartesian=T)
# remove 0s, since this will be multiplied by the random effect and thus contribute nothing to the total value for that year
re1 <- re1[y_spline_value != 0]
re1 <- merge(re1, s_age, by="a_spline", allow.cartesian=T)
# remove 0s again
re1 <- re1[a_spline_value != 0]

gc()

# simvars
re1<-re1[, (simvars) := lapply(.SD, function(x) sum(x*y_spline_value*a_spline_value)),
         .SDcols=simvars, by=c("area", "race", "edu", "age", "year")]
del_vars <- c("y_spline", "y_spline_value", "a_spline", "a_spline_value")
re1 <- re1[, (del_vars) := NULL]
re1 <- unique(re1)

setkeyv(re1, c("year", "age", "area", "race", "edu"))
re <- as.matrix(re1[data[, list(year, age, area, race, edu)], simvars, with = F])

if (any(is.na(re))) {stop("re1 has NA values")} # checks re, but says re1, b/c re is just re1 at this point

re2 <- data.table(as.matrix(sims[names(mean) == "re2", ]))
##Sum the initial random effects (re1 and re2) by adding re2 into re

## Area effect
re2[, area := indexed_areas]
setkeyv(re2, "area")

if (any(is.na(re2))) {stop("re2 has NA values")}

re <- re + as.matrix(re2[data[, list(area)], simvars, with = F])

if (any(is.na(re))) {stop("after adding re2, re has NA values")}


# Now, read in the 3rd random effect

re3 <- data.table(as.matrix(sims[names(mean) == "re3", ]))

combos <- as.data.table(
  expand.grid(
    year = as.integer(as.factor(years)) - 1,
    age = as.integer(as.factor(ages)) -
      1,
    race = races_to_model,
    edu = edus_to_model
  )
)

stopifnot(nrow(re3) == nrow(combos))
re3 <- cbind(re3, combos)

if (any(is.na(re3))) {
  stop("re3 has NA values")
}

setkeyv(re3, c("year", "race", "edu", "age"))

# Add all random effects together (re1 and re2 already summed earlier)
re <- re +
  as.matrix(re3[data[, list(year, race, edu, age)], simvars, with = F])


if (any(is.na(re))) {
  stop("after adding re3, re has NA values")
}

message(glue::glue("Working on sub-population covariate effects for model {model}..."))

covar_subpop_random_effects <- data.table(as.matrix(sims[names(mean) == "covar_subpop_re_matrix", ]))
if (nrow(covar_subpop_random_effects) == 0) {
  stop("covar_subpop_random_effects has 0 rows: nothing named covar_subpop_re_matrix in mean.")
}

message(glue::glue("covar_subpop_random_effects has {nrow(covar_subpop_random_effects)} rows."))

# add in the effect of the race/ethnicity or edu specific covariates by iterating over each of the race/ethnicity or edu specific covariates
for (i in c(1:length(covars_subpop))) {
  message(glue::glue("Working on covariate number {i}: {covars_subpop[i]}"))
  
  chunk_size <- nrow(covar_subpop_random_effects) / length(covars_subpop)
  message(glue::glue("chunk_size = {chunk_size}"))

  # the row/index that marks the end of the current covariates chunk of covar_subpop_re_matrix
  end_row <- chunk_size * i

  # create an index that identifies the correct rows of covar_subpop_re_matrix. Add 1 at the start so that the index begins at 1, because row numbers in data.table begins at 1.
  begin_row <- end_row - chunk_size + 1
  message(glue::glue("begin_row is {begin_row}"))
  message(glue::glue("end_row is {end_row}"))

  covar_subpop_random_effect_rows <- c((begin_row):(end_row))
  message(glue::glue("covar_subpop_random_effect_rows is {paste(covar_subpop_random_effect_rows, collapse=',')}"))

  # check that the number of rows is correct
  if (length(covar_subpop_random_effect_rows) != chunk_size) {
    stop(glue::glue("covar_subpop_random_effect_rows should be of length {chunk_size} but instead it has length {length(covar_subpop_random_effect_rows)}"))
  }

  # subset / pull out the rows that are for this covariate
  covar_subpop_random_effect <- covar_subpop_random_effects[covar_subpop_random_effect_rows, ]

  # check that the number of rows is correct
  if (nrow(covar_subpop_random_effect) != chunk_size) {
    stop(glue::glue("covar_subpop_random_effect should be of length {chunk_size} but instead it has {nrow(covar_subpop_random_effect)} rows"))
  }

  # include race and edu so that it can be merged onto the data
  covar_subpop_random_effect[, race := races_to_model]
  covar_subpop_random_effect[, edu := edus_to_model]
  setkeyv(covar_subpop_random_effect, c("race", "edu"))

  # pull out the current covariate
  covar_random_effect <- data[, get(covars_subpop[i])]

  # Add these race/ethnicity covariate slopes to the other random effects
  message("adding to re...")
  
  re <- re + (covar_random_effect * covar_subpop_random_effect[data[, list(race, edu)], simvars, with = F])
  if (any(is.na(re))) {stop("after adding covar_subpop_random_effect, re has NA values")}
  message(glue::glue("Done with loop {i}."))
} # end race/ethnicity covariate random effect for loop

message(glue::glue("Done with sub-population covariate effects for model {model}"))


message(glue::glue("Working on shocks indicator model {model} (for models with 2 indicators)..."))

re4 <- data.table(as.matrix(sims[names(mean) == "re4", ]))
re4[, area := 1:num_j - 1L]
setkeyv(re4, "area")

re <- re + data$indic_1 * as.matrix(re4[data[, list(area)], simvars, with = F])

re5 <- data.table(as.matrix(sims[names(mean) == "re5", ]))
re5[, area := 1:num_j - 1L]
setkeyv(re5, "area")

re <- re + data$indic_2 * as.matrix(re5[data[, list(area)], simvars, with = F])

## now the age effects
re6 <- data.table(as.matrix(sims[names(mean) == "re6", ]))
re6[, age := 1:num_a - 1L]
setkeyv(re6, "age")

re <- re + data$indic_1 * as.matrix(re6[data[, list(age)], simvars, with = F])

re7 <- data.table(as.matrix(sims[names(mean) == "re7", ]))
re7[, age := 1:num_a - 1L]
setkeyv(re7, "age")

re <- re + data$indic_2 * as.matrix(re7[data[, list(age)], simvars, with = F])

if (any(is.na(re))) {stop("after adding effects for shocks indicators, re has NA values")}


message(glue::glue("Processing random effect for offset covariate in model {model}..."))

if (!("covar_offset_random_effect" %in% unique(names(mean)))) {
  stop("covar_offset_random_effect is not in the names of mean.")
}

# need state attached to data, (since the random effect for offset is by state), for when
# data and the offset covariate random effect are joined.
loc <- fread('FILEPATH/merged_counties.csv')
if (!("state") %in% names(data)) {
  if ("state.x" %in% names(data)) data[, state.x := NULL]
  if ("state.y" %in% names(data)) data[, state.y := NULL]
  data <- merge(data, unique(loc[, .(mcnty, state)]), by.x = "area", by.y = "mcnty", all.x = T)
}

if (any(is.na(data$state))) stop("state column of data has NA values")

# Generate labels for the offset covariate. If this is done correctly for re3 above, which
# also has 3 dimensions, then this is also correct. It appears that if expand grid is given
# dimensions in the same order that the random effect's dimensions were specified and used,
# then combos' row order should be the same as the random effect's row order
combos <- as.data.table(expand.grid(
  race = races_to_model, # not encoded in data
  edu = edus_to_model, # not encoded
  age = as.integer(as.factor(ages)) - 1, # encoded in data
  state = sort(unique(loc$state))
))

merge_vars <- c("race", "edu", "age", "state")

# pull out the fitted random effect from sims
covar_offset_random_effect <-
  data.table(as.matrix(sims[names(mean) == "covar_offset_random_effect",]))

# simple test to check that we at least have the correct dimensions

stopifnot(nrow(covar_offset_random_effect) == nrow(combos))

covar_offset_random_effect <- merge(x = covar_offset_random_effect,
                                    y = data,# data must be on right
                                    by = merge_vars,
                                    all.y = T, # don't remove this, we want to show that it's a right outer join
                                    allow.cartesian = T
)

setkeyv(covar_offset_random_effect, c("area", "year", "sex", "race", "edu", "age")) # set row order, using pred_inputs order for data
if (any(is.na(covar_offset_random_effect))) {
  stop("NAs in covar_offset_random_effect, probable bad merge.")
}

if (nrow(covar_offset_random_effect) != nrow(data)) {
  stop("data and covar_offset_random_effect do not have the same number of rows. Multiplication will not work.")
}

# remove state column
data[, state := NULL]

# multiply by the covariate itself (in data) by the random effect for the offset covariate
message("Taking product of the covar_offset random effect with the covariate...")

# covar_subpop_random_effect. This would ensure the row orders match.
covar_offset_random_effect <- data[, get(covars_offset)] * covar_offset_random_effect[, simvars, with = F]

# if zero_covar_offset is true, then the predictions for this effect should all be zero
if (zero_covar_offset) {
  zeros <- data.table(matrix(0, nrow = nrow(covar_offset_random_effect), ncol = ncol(covar_offset_random_effect)))
  stopifnot(all.equal(target = zeros, current = covar_offset_random_effect))
}

# check that dimensions match
stopifnot(identical(dim(re), dim(covar_offset_random_effect)))

message("adding to re...")
re <- re + as.matrix(covar_offset_random_effect)
if (any(is.na(re))) {stop("after adding covar_offset_random_effect, re has NA values")}

message("Done with random effect for offset covariate.")


## calculate mx and combine with identifying information -------------------------------------------

draws <- fe + re

if(model == "spline_iid_flexible_re_covs_offset") {

  offset <- as.matrix(data[, c(offsets), with = F])
  # we just want to add the offset to every draw, so replicate it based on the draw width
  offset_draws <- offset %*% matrix(1, nrow = 1, ncol = length(draw_val))

  draws <- draws + offset_draws

}

rm(fe, re); gc()

draws <- data.table(exp(draws))

draws[, area := as.integer(data$area)]
draws[, sex := as.integer(data$sex)] # this should work whether sex_together is true or false

# Decoding year and age
draws[, year := as.integer(data$year + years[1])]
draws[, age := as.integer(ages[1 + data$age])]

# Decoding race and edu
if(is.factor(data$race)) {
  draws[, race := as.integer(as.character(data$race))]
} else {
  draws[, race := as.integer(data$race)]
}

draws[, edu := as.integer(data$edu)]

## Split out draws by year, calculate all-ages, age-standardized draws, collapse draws, and save ---
# load and subset the population file, then merge onto draws
pop <- readRDS(pop_file)
if (!by_race) {
  pop[, race := all_pop_id]
}

if (!by_edu) {
  pop[, edu := all_pop_id]
}

# filter pop depending on the values of race_together and edu_together
# in any case, subset pop to the current sex and years
if(!sex_together) {
  pop <- pop[sex == get("sex", .GlobalEnv)]
}

pop <- pop[sex %in% sexes & year %in% get("years", .GlobalEnv), ] # but, we do want to subset to the sexes for each cause so that we respect the sex restrictions

pop <- pop[race %in% unique(data$race) & edu %in% unique(data$edu), ]

if (by_edu & setequal(ages, seq(25, 85, 5))) {
  pop <- pop[age %in% ages, ]
}

# now that all filtering is done, aggregate pop. We'll aggregate the same way regardless of the values
# of race_together or edu_together.
pop <- pop[, list(pop = sum(pop)), by = c(area_var, "year", "age", "race", "edu", "sex")] # sex added back into the merge so that sex_together models will work

# if race is a factor (because of processing), convert to integer
if(is.factor(pop$race)) pop[,race := as.integer(as.character(race))]

# merge has all = TRUE so that every age group in pop is included is present after the merge.
# That is, this merge introduces ages that might be restricted, depending on the cause.
# After uses the merge to add every age group, this code then fills in nulls that the merge made
# with zeros. Having every age group is critical for the calculation of age-standardized and

# We want restricted ages to have values of zero.

setnames(pop, area_var, "area")

# set merge variables for later
draws <- merge(draws, pop, by = c("area", "year", "age", "edu", "race", "sex"), all = TRUE)  

# Check that every age group is present before proceeding. Every age group has to be present in
# order for the age standardized mortality rate to be correct. For by-edu infant and adult modeling,
# don't do this check. This if statement says "If ages is just infants OR if ages is just adults, and
# by_edu is T, then do not run calc_all_ages".
if (!((setequal(ages, c(0)) |
       setequal(ages, seq(25, 85, 5))) &
      by_edu)) {
  stopifnot(setequal(unique(draws$age),
                     c(0, 1, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85)))
}

# If a validation model, subset the data so that predictions are generated only for the validation
# set However, keep all race/ethnicities in the counties that are in the validation set. That is,
# keep all the counties in the validation set.
if (validate) {
  gs_mx <- readRDS(gs_file)
  gs_mx <- gs_mx[year %in% years, ]
  # drop race and edu because we want to keep all races in counties that have at least one race in
  # the validation set
  gs_mx[, `:=`(race = NULL, edu = NULL)]
  # get rid of duplicates in the counties that had more than one race
  gs <- unique(gs_mx[sex == get("sex", .GlobalEnv),
                     list(area = get(area_var))])
  draws <- merge(gs, draws, by = c("area"), all.x = T)
  stopifnot(!any(is.na(draws)))
  setkeyv(draws, c("area", "year"))
  rm(gs, gs_mx)
  gc()
}

# This is part of the introduction of every age group. We want restricted ages to have values of zero.
# All other nulls are in ages that are not in the original data file (age restricted)
# Define a function to yield either 0 or x, depending on if x is null
# replace nulls among rows for ages that are restricted and columns that are draws aka simvars
replace_na_func <- function(x) ifelse(is.na(x), 0, x)
draws[!(age %in% ages), (simvars) := lapply(.SD, replace_na_func), .SDcols = simvars]

# No missing values are expected
stopifnot(!any(is.na(draws)))

## Set draws for particular ages to 0 for some drug use causes
set_draws_0 <- function(x) 0

if("cause_id" %in% ls(envir = .GlobalEnv)) {
  if(!is.null(cause_id)) {
    if(cause_id %in% c(561, 562)) {
      draws[age %in% c(1,5,10), (simvars) := lapply(.SD, set_draws_0), .SDcols = simvars]
    }
  }
}

# load the age standard
std_wt <- readRDS(age_std_file)[, list(age, wt = wt / sum(wt))]

# split up data and process separately by year
all_draws <- draws
rm(draws)


if ("misclassification_draws.rds" %in% list.files(dir, full.names = F)) {
  # assume that the user wants to use the misclassification draws that are all combined
  mc <- readRDS(paste0(dir, "/misclassification_draws.rds"))
}


all_draws <- lapply(years, function(this_year) all_draws[year == this_year, ])
for (this_year in years) {
  ## Check if the final file already exists if resubmission is specified
  if(sex_together) {
    expected_files <- c()
    for(s in sexes) {
      expected_files <- c(expected_files, paste0(dir, "/mx_est_mcnty_", this_year, "_", s, "_", unique(data$race), "_", unique(data$edu), ".rds"))
    }
  } else {
    expected_files <- paste0(dir, "/mx_est_mcnty_", this_year, "_", sex, "_", unique(data$race), "_", unique(data$edu), ".rds")
  }


  
  stopifnot(!(by_race & by_edu))

  if(resub & all(file.exists(expected_files))) {

    all_draws[[which(years == this_year)]] <- NA
    message("Skipping")

  } else {
    cat(paste(Sys.time(), this_year, "\n"))
    draws <- all_draws[[which(years == this_year)]]
    draws[, level := area_var]
    if (nrow(draws) == 0) next # this can happen in validation models

    # reshape long for easier processing
    draws <- melt(draws, id.vars = c("level", "area", "year", "sex", "race", "edu", "age", "pop"), variable.name = "sim", value.name = "mx")

    draws[, sim := as.integer(sim)]
    # re-code the draws to correspond to draw_val
    draws[, sim := sim + (min(draw_val) - 1)]

    # specify the columns by which to summarize/aggregate/etc since now we have both adjusted and unadjusted points
    # this is used for the calc_all_ages function
    all_age_by_vars <- c("level", "area", "year", "sex", "race", "edu", "sim")

    # if applying the misclassication ratios, look for a file saved with these
    if ("misclassification_draws.rds" %in% list.files(dir, full.names = F)) {

      # Specify the columns by which to merge misclassification draws and the prediction draws. This
      # is happening inside the loop because that's where draws is reshaped and has more columns
      # specified.
      mc_merge_vars <- c("sim", "sex", "race", "edu", "age", "area") # initialize / reset
      cols_intersect <- intersect(names(draws), names(mc))
      mc_merge_vars <- intersect(mc_merge_vars, cols_intersect)
      message(glue::glue("Merge columns for misclassification are {paste(mc_merge_vars, collapse=', ')}."))

      draws <- merge(draws, mc, by = mc_merge_vars, all.x = T)
      if (nrow(draws[is.na(ratio)]) > 0) stop("Classification ratios did not merge on correctly")

      # save the pre-mislcassification adjusted
      # this will make the draws ridiculously large, but this will be easiest moving through the pipeline
      draws_temp <- copy(draws)[, adjusted := 0]
      draws <- rbind(draws_temp, draws[, c("mx", "adjusted") := list(mx*ratio, 1)], use.names = TRUE)
      draws[, ratio := NULL]
      all_age_by_vars <- c(all_age_by_vars, "adjusted")
    } else if (by_race) {

      draws[,adjusted := 1] # if by-race but not using a misclassification adjustment, just set the adjusted column to 1
      all_age_by_vars <- c(all_age_by_vars, "adjusted")

    }

    # add crude and age-standardized rates
    draws <- calc_all_ages(draws, std_wt, "mx", by_vars = all_age_by_vars, allow_missing_ages = by_edu)

    # save draws and estimates
    
    if(sex_together) {
      sexes_to_model <- sexes
    } else {
      sexes_to_model <- sex
    }

    for(s in sexes_to_model) {
      for (r in races_to_model) {
        for(e in edus_to_model) {
          message(paste0("Working on race ", r))
          message(paste0("Working on edu ", e))
          message(paste0("Working on sex ", s))

          saveRDS(draws[race == r & edu == e & sex == s], file = paste0(dir, "/mx_draws_", area_var, "_", this_year, "_", s, "_",
                                                                        r, "_", e, "_",
                                                                        max(draw_val), ".rds"))
        }

      }
    }


    all_draws[[which(years == this_year)]] <- NA
    rm(draws); gc()
  }
}

# If there are warnings, display them:
warnings()

message("DONE.")
